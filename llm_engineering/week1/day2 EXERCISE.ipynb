{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, and even entire books. This can help businesses save time and resources while maintaining a consistent tone and style.\n",
      "2. **Product Design**: Generative AI can be used to design new products, packaging, and even entire product lines. This can help businesses quickly test and iterate on designs without requiring significant upfront investment.\n",
      "3. **Marketing and Advertising**: Generative AI can be used to generate personalized marketing campaigns, ad copy, and social media content. This can help businesses tailor their messaging to specific customer segments and improve engagement rates.\n",
      "4. **Customer Service**: Generative AI-powered chatbots can be used to provide 24/7 customer support, answering common questions and routing complex issues to human representatives.\n",
      "5. **Data Analysis**: Generative AI can be used to analyze large datasets, identify patterns, and predict trends. This can help businesses make data-driven decisions and gain a competitive edge.\n",
      "6. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations, predicting demand, managing inventory, and identifying potential bottlenecks.\n",
      "7. **Financial Modeling**: Generative AI can be used to create complex financial models, simulating different scenarios and forecasting future outcomes.\n",
      "8. **Creative Writing**: Generative AI can be used to generate creative content such as music, poetry, or even entire scripts.\n",
      "9. **Education and Training**: Generative AI can be used to create personalized learning experiences, generating customized lessons, quizzes, and assessments.\n",
      "10. **Healthcare**: Generative AI can be used to analyze medical data, identify patterns, and predict patient outcomes.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Chatbots**: Many businesses are using chatbots to provide 24/7 customer support and improve the overall customer experience.\n",
      "* **Virtual Assistants**: Companies like Microsoft and Amazon are using virtual assistants to power their customer service operations.\n",
      "* **Marketing Automation**: Generative AI can be used to automate marketing campaigns, sending personalized emails and messages to customers based on their behavior and preferences.\n",
      "* **Product Development**: Generative AI can be used to design new products, reducing the time and cost associated with traditional product development processes.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses of Generative AI in various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create personalized content, such as articles, social media posts, and product descriptions, reducing the need for human writers and increasing efficiency.\n",
      "2. **Marketing Automation**: Generative AI can generate email campaigns, ads, and promotional materials that are tailored to individual customers' interests, increasing engagement and conversion rates.\n",
      "3. **Product Design**: Generative AI can design new products, such as furniture, fashion items, or electronics, using computer-aided design (CAD) software, reducing the need for human designers and speeding up the product development process.\n",
      "4. **Data Analysis**: Generative AI can analyze large datasets, identify patterns, and make predictions, helping businesses gain insights into customer behavior, market trends, and operational efficiency.\n",
      "5. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants that provide 24/7 customer support, answering common questions, and routing complex issues to human representatives.\n",
      "6. **Personalized Recommendations**: Generative AI can generate personalized product recommendations for e-commerce websites, increasing sales and improving customer satisfaction.\n",
      "7. **Creative Writing and Storytelling**: Generative AI can be used to create original stories, poems, and scripts, reducing the need for human writers and increasing the efficiency of content creation.\n",
      "8. **Music and Audio Generation**: Generative AI can generate music, sound effects, and audio tracks, opening up new possibilities for music composition, advertising, and entertainment.\n",
      "9. **Image and Video Editing**: Generative AI can edit images and videos, removing noise, correcting imperfections, and enhancing the overall aesthetic of visual content.\n",
      "10. **Predictive Maintenance**: Generative AI can analyze equipment performance data to predict maintenance needs, reducing downtime and increasing overall efficiency in industries like manufacturing and logistics.\n",
      "\n",
      "In specific industries, some notable business applications of generative AI include:\n",
      "\n",
      "* **Healthcare**: Generative AI can help develop personalized treatment plans, generate medical images, and analyze patient data to identify potential health risks.\n",
      "* **Finance**: Generative AI can be used to analyze financial data, predict market trends, and automate investment decisions.\n",
      "* **Education**: Generative AI can create personalized learning materials, grade assignments, and provide adaptive feedback for students.\n",
      "* **Supply Chain Management**: Generative AI can optimize logistics, predict demand, and manage inventory levels.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963c0f71-7010-4647-9437-5f41051f2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "628d669c-5dfb-42bc-b1e5-a4477e429a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84c2de4-6893-4c95-aa52-adc68f8c6a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6fac7-9d38-45e6-b80c-f89cf65f1c0f",
   "metadata": {},
   "source": [
    "Types of prompts\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "A system prompt that tells them what task they are performing and what tone they should use\n",
    "\n",
    "A user prompt -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3cd6d17-bd94-491f-88f7-8fc3965d2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d654de66-ea98-4d7b-a129-d1a2df5016df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcca53-cc8e-4c67-8b49-f695ee1116c1",
   "metadata": {},
   "source": [
    "Messages\n",
    "The API from Ollama expects the same message format as OpenAI:\n",
    "\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c51ba7-bc57-4c25-a561-ffb081a89b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b093c-3359-4a83-904a-c51fd0eb757f",
   "metadata": {},
   "source": [
    "## Time to bring it together - now with Ollama instead of OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920555c0-b59d-4c10-8577-893b7e5f8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Ollama function instead of OpenAI\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    messages = messages_for(website)\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1b0058-ecbd-4c10-a3d8-d3187cebc22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Summary of Edward Donner\\'s Website\\n\\n#### Overview\\nThis website belongs to Edward Donner, a co-founder and CTO of Nebula.io, an AI company that applies artificial intelligence to help people discover their potential. He is also the founder and CEO of AI startup untapt.\\n\\n#### Recent News and Announcements\\n- **May 28, 2025**: \"Connecting my courses – become an LLM expert and leader\"\\n- **May 18, 2025**: \"2025 AI Executive Briefing\"\\n- **April 21, 2025**: \"The Complete Agentic AI Engineering Course\"\\n- **January 23, 2025**: \"LLM Workshop – Hands-on with Agents – resources\"\\n\\n#### Content\\nThe website provides information about Edward Donner\\'s work in the field of artificial intelligence, specifically his roles in Nebula.io and untapt. It also includes links to his social media profiles and a newsletter subscription form.\\n\\n#### Notable Features\\n\\n- **Outsmart Arena**: An arena where Large Language Models (LLMs) are pitted against each other in a battle of diplomacy and deviousness.\\n- **Hacker News Mention**: Edward Donner is mentioned on Hacker News, indicating he participates in discussions related to technology and innovation.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "295437eb-5c30-452c-8947-dc97e0e4370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a255846-fc6d-41fe-86c0-8337ee02a8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**\n",
       "\n",
       "* Edward Donner is a co-founder and CTO of Nebula.io, applying AI to help people discover their potential.\n",
       "* He is also the founder and former CEO of AI startup untapt, acquired in 2021.\n",
       "\n",
       "**News/Announcements**\n",
       "\n",
       "* Upcoming courses:\n",
       "\t+ \"Connecting my courses – become an LLM expert and leader\" (May 28, 2025)\n",
       "\t+ \"The Complete Agentic AI Engineering Course\" (January 23, 2025)\n",
       "\t+ \"LLM Workshop – Hands-on with Agents – resources\"\n",
       "\t+ 2025 AI Executive Briefing (April 21, 2025)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
